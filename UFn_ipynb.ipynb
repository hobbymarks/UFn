{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "judicial-strength",
   "metadata": {},
   "source": [
    "## Set Target Directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "signal-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All files in target_dir will be Unified file name,include directorys.\n",
    "# You should change target_dir string manually .\n",
    "# You should better use absolute directory path .\n",
    "target_dir = \"../EmptyDir/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-wilderness",
   "metadata": {},
   "source": [
    "## Desfine Set and Also Pickle to File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interested-judgment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T09:34:13.207712Z",
     "iopub.status.busy": "2021-03-09T09:34:13.207492Z",
     "iopub.status.idle": "2021-03-09T09:34:13.210539Z",
     "shell.execute_reply": "2021-03-09T09:34:13.209881Z",
     "shell.execute_reply.started": "2021-03-09T09:34:13.207688Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = \"./data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-filing",
   "metadata": {},
   "source": [
    "#### Define Characters Set Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "potential-tanzania",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-08T11:44:21.586685Z",
     "iopub.status.busy": "2021-03-08T11:44:21.586478Z",
     "iopub.status.idle": "2021-03-08T11:44:21.598625Z",
     "shell.execute_reply": "2021-03-08T11:44:21.597770Z",
     "shell.execute_reply.started": "2021-03-08T11:44:21.586661Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "CharDictionary = collections.OrderedDict()\n",
    "specChar = \"_\"\n",
    "CharDictionary = {\n",
    "    \"\\r\": specChar,\n",
    "    \"\\n\": specChar,\n",
    "    \"?\": specChar,\n",
    "    \",\": specChar,\n",
    "    \"!\": specChar,\n",
    "    \":\": specChar,\n",
    "    \"&\": specChar,\n",
    "    \"@\": specChar,\n",
    "    \"¬∑\": specChar,  #at the middle height of row\n",
    "    \"\\`\": specChar,\n",
    "    \" \": specChar,\n",
    "    \"(\": specChar,\n",
    "    \")\": specChar,\n",
    "    \"'\": specChar,\n",
    "    \"+\": specChar,\n",
    "    \"-\": specChar,\n",
    "    \"=\": specChar,\n",
    "    \"|\": specChar,\n",
    "    \"[\": specChar,\n",
    "    \"]\": specChar,\n",
    "    \"{\": specChar,\n",
    "    \"}\": specChar,\n",
    "    \"¬ª\": specChar,\n",
    "    \"¬´\": specChar,\n",
    "    \"\\\"\": specChar,\n",
    "    \"*\": specChar,\n",
    "    \"#\": specChar,\n",
    "    \"¬Æ\": specChar,\n",
    "    \"‚Ä¶\": specChar,\n",
    "    \"‚Äú\": specChar,\n",
    "    \"‚Äù\": specChar,\n",
    "    #     \".\": specChar,\n",
    "    \"‚Ä¢\": specChar,\n",
    "    \"Ôºå\": specChar,\n",
    "    \"‚Äì\": specChar,\n",
    "    \"‚Äî\": specChar,\n",
    "    #     \"‰∏Ä\": specChar,#It is a chinese number character, means one\n",
    "    \"„ÄÅ\": specChar,\n",
    "    \"Ôºà\": specChar,\n",
    "    \"Ôºâ\": specChar,\n",
    "    \"„Ää\": specChar,\n",
    "    \"„Äã\": specChar,\n",
    "    \">\": specChar,\n",
    "    \"„Äê\": specChar,\n",
    "    \"„Äë\": specChar,\n",
    "    \"„Äå\": specChar,\n",
    "    \"„Äç\": specChar,\n",
    "    \"ÔΩú\": specChar,\n",
    "    \"Ôºö\": specChar,\n",
    "    \"Ôºõ\": specChar,\n",
    "    \"Ôºü\": specChar,\n",
    "    \"ÔºÅ\": specChar,\n",
    "    \"üöÄ\": specChar,\n",
    "    \"üö¥\": specChar,\n",
    "    \"üåè\": specChar,\n",
    "    \"üêæ\": specChar,\n",
    "    \"%2F\": specChar,\n",
    "    \"____\": specChar,\n",
    "    \"___\": specChar,\n",
    "    \"__\": specChar,\n",
    "    \"._\": specChar,\n",
    "    \"What‚Äôs\": \"What_is\",\n",
    "    \"what‚Äôs\": \"what_is\"\n",
    "}\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "fname = \"CharDictionary_\" + datetime.now().strftime(\"%Y%m%d\" + \".pkl\")\n",
    "fpath = os.path.join(data_path, fname)\n",
    "lnkpath = os.path.join(data_path, \"CharDictionary.pkl\")\n",
    "\n",
    "with open(fpath, \"wb\") as fhand:\n",
    "    pickle.dump(CharDictionary, fhand)\n",
    "\n",
    "import subprocess\n",
    "\n",
    "if os.path.exists(lnkpath):\n",
    "    os.remove(lnkpath)\n",
    "createLink = subprocess.Popen([\"ln\", \"-s\", fname, lnkpath])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-right",
   "metadata": {},
   "source": [
    "#### Define Terminology Set Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "solid-question",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T09:38:16.884520Z",
     "iopub.status.busy": "2021-03-09T09:38:16.884324Z",
     "iopub.status.idle": "2021-03-09T09:38:16.894090Z",
     "shell.execute_reply": "2021-03-09T09:38:16.893348Z",
     "shell.execute_reply.started": "2021-03-09T09:38:16.884497Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TerminologyDictionary = {\n",
    "    #     \"apple\": \"Apple\",\n",
    "    \"api\": \"API\",\n",
    "    \"atm\": \"ATM\",\n",
    "    \"cmsis\": \"CMSIS\",\n",
    "    \"cypress\": \"CYPRESS\",\n",
    "    \"dji\": \"DJI\",\n",
    "    #     \"google\": \"Google\",\n",
    "    \"i2c\": \"I2C\",\n",
    "    \"kicad\": \"KiCAD\",\n",
    "    \"mbed\": \"Mbed\",\n",
    "    \"mosfet\": \"MOSFET\",\n",
    "    \"mux\": \"MUX\",\n",
    "    \"nltk\": \"NLTK\",\n",
    "    \"nucleo\": \"NUCLEO\",\n",
    "    \"pcb\": \"PCB\",\n",
    "    \"pcie\": \"PCIe\",\n",
    "    \"psoc\": \"PSoC\",\n",
    "    \"rohs\": \"ROHS\",\n",
    "    \"spi\": \"SPI\",\n",
    "    \"stm32\": \"STM32\",\n",
    "    \"stmicroelectronics\": \"STMicroelectronics\",\n",
    "    \"ti\": \"TI\",\n",
    "    \"usb\": \"USB\",\n",
    "    \"vishay\": \"VISHAY\",\n",
    "}\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "fname = \"TerminologyDictionary_\" + datetime.now().strftime(\"%Y%m%d\" + \".pkl\")\n",
    "fpath = os.path.join(data_path, fname)\n",
    "lnkpath = os.path.join(data_path, \"TerminologyDictionary.pkl\")\n",
    "with open(fpath, \"wb\") as fhand:\n",
    "    pickle.dump(TerminologyDictionary, fhand)\n",
    "\n",
    "import subprocess\n",
    "\n",
    "if os.path.exists(lnkpath):\n",
    "    os.remove(lnkpath)\n",
    "createLink = subprocess.Popen([\"ln\", \"-s\", fname, lnkpath])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-advertising",
   "metadata": {},
   "source": [
    "#### Define Ignored Directory Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bored-extension",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T11:17:31.269301Z",
     "iopub.status.busy": "2021-03-02T11:17:31.269003Z",
     "iopub.status.idle": "2021-03-02T11:17:31.286894Z",
     "shell.execute_reply": "2021-03-02T11:17:31.285873Z",
     "shell.execute_reply.started": "2021-03-02T11:17:31.269264Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IgnoredDirectoryKeyList = [\".git\", \".xcodeproj\", \".cydsn\", \".cywrk\"]\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "fname = \"IgnoredDirectoryKeyList_\" + datetime.now().strftime(\"%Y%m%d\" + \".pkl\")\n",
    "fpath = os.path.join(data_path, fname)\n",
    "lnkpath = os.path.join(data_path, \"IgnoredDirectoryKeyList.pkl\")\n",
    "with open(fpath, \"wb\") as fhand:\n",
    "    pickle.dump(IgnoredDirectoryKeyList, fhand)\n",
    "\n",
    "import subprocess\n",
    "\n",
    "if os.path.exists(lnkpath):\n",
    "    os.remove(lnkpath)\n",
    "createLink = subprocess.Popen([\"ln\", \"-s\", fname, lnkpath])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-contract",
   "metadata": {},
   "source": [
    "#### Get Words Set and Convert to Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "homeless-browse",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T10:43:27.616964Z",
     "iopub.status.busy": "2021-03-02T10:43:27.616741Z",
     "iopub.status.idle": "2021-03-02T10:43:28.481241Z",
     "shell.execute_reply": "2021-03-02T10:43:28.480294Z",
     "shell.execute_reply.started": "2021-03-02T10:43:27.616937Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "LowerCaseWordSet = set(list(map(lambda x: x.lower(), words.words())))\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "with open(\n",
    "        os.path.join(\n",
    "            data_path,\n",
    "            \"NLTK_corpus_words_\" + datetime.now().strftime(\"%Y%m%d\") + \".pkl\"),\n",
    "        \"wb\") as fhand:\n",
    "    pickle.dump(words.words(), fhand)\n",
    "\n",
    "fname = \"LowerCaseWordSet_\" + datetime.now().strftime(\"%Y%m%d\" + \".pkl\")\n",
    "fpath = os.path.join(data_path, fname)\n",
    "lnkpath = os.path.join(data_path, \"LowerCaseWordSet.pkl\")\n",
    "with open(fpath, \"wb\") as fhand:\n",
    "    pickle.dump(LowerCaseWordSet, fhand)\n",
    "\n",
    "import subprocess\n",
    "\n",
    "if os.path.exists(lnkpath):\n",
    "    os.remove(lnkpath)\n",
    "createLink = subprocess.Popen([\"ln\", \"-s\", fname, lnkpath])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-boating",
   "metadata": {},
   "source": [
    "---\n",
    "## Jupyter Notebook Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-analysis",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "religious-worcester",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replaceChar(charDict={}, tgtString=\"\"):\n",
    "    assert charDict\n",
    "    assert tgtString\n",
    "    print(tgtString)\n",
    "    import os\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    for key, value in charDict.items():\n",
    "        if key in root:\n",
    "            root = root.replace(key, value)\n",
    "            print(\"---%s\" % root + ext)\n",
    "    return root + ext\n",
    "\n",
    "\n",
    "def processHeadTailChar(tgtString=\"\"):\n",
    "    assert tgtString\n",
    "    specChar = \"_\"\n",
    "    import os\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    if root.startswith(specChar):\n",
    "        root = specChar.join(root.split(specChar)[1:])\n",
    "    if root.endswith(specChar):\n",
    "        root = specChar.join(root.split(specChar)[0:-1])\n",
    "    return root + ext\n",
    "\n",
    "\n",
    "def processTerminology(termDictionary={}, tgtString=\"\"):\n",
    "    assert termDictionary\n",
    "    assert tgtString\n",
    "    specChar = \"_\"\n",
    "    import os\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    wordList = root.split(specChar)\n",
    "    newWordList = []\n",
    "    for word in wordList:\n",
    "        if word.lower() in termDictionary.keys():\n",
    "            newWordList.append(termDictionary[word.lower()])\n",
    "        else:\n",
    "            newWordList.append(word)\n",
    "    return specChar.join(newWordList) + ext\n",
    "\n",
    "\n",
    "def titlelize(tgtString=\"\"):\n",
    "    assert tgtString\n",
    "    import os\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    return root.title() + ext\n",
    "\n",
    "\n",
    "def processWord(wordSet=set(), tgtString=\"\"):\n",
    "    assert wordSet\n",
    "    assert tgtString\n",
    "    specChar = \"_\"\n",
    "    import os\n",
    "    import string\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    wordList = root.split(specChar)\n",
    "    newWordList = []\n",
    "    for word in wordList:\n",
    "        if word.lower() in wordSet:\n",
    "            newWordList.append(string.capwords(word))\n",
    "        else:\n",
    "            newWordList.append(word)\n",
    "\n",
    "    return specChar.join(newWordList) + ext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-batch",
   "metadata": {},
   "source": [
    "### Processing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "personal-macintosh",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for subdir, dirs, files in os.walk(target_dir):\n",
    "    for file in files:\n",
    "        oldNamePath = os.path.join(subdir, file)\n",
    "        #         newName = \"\".join(file.split())\n",
    "        newName = file\n",
    "        # replace characters by defined Dictionary\n",
    "        newName = replaceChar(charDict=CharDictionary, tgtString=newName)\n",
    "        # process Head and Tail character exclude file name extension\n",
    "        newName = processHeadTailChar(tgtString=newName)\n",
    "        # Capitalize\n",
    "        #         newName = newName.capitalize()\n",
    "        # Titlelize File Name\n",
    "        #         newName = titlelize(tgtString=newName)\n",
    "        # Capwords only when word in wordsSet\n",
    "        newName = processWord(wordSet=LowerCaseWordSet, tgtString=newName)\n",
    "        # Pretty Terminology\n",
    "        newName = processTerminology(termDictionary=TerminologyDictionary,\n",
    "                                     tgtString=newName)\n",
    "        # Create full path\n",
    "        newNamePath = os.path.join(subdir, newName)\n",
    "        # rename file name\n",
    "        os.rename(oldNamePath, newNamePath)\n",
    "        print(\"==>%s\" % newName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-appearance",
   "metadata": {},
   "source": [
    "---\n",
    "## Standalone Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "offensive-winning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T10:12:39.547926Z",
     "iopub.status.busy": "2021-03-09T10:12:39.547746Z",
     "iopub.status.idle": "2021-03-09T10:12:39.552203Z",
     "shell.execute_reply": "2021-03-09T10:12:39.551827Z",
     "shell.execute_reply.started": "2021-03-09T10:12:39.547906Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting UFn.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile UFn.py\n",
    "\n",
    "import hashlib\n",
    "import collections\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import string\n",
    "import click\n",
    "\n",
    "\n",
    "class FileNameLog:\n",
    "\n",
    "    def __init__(self, filePath=\"\", md5Value=\"\"):\n",
    "        if not md5Value:\n",
    "            assert os.path.exists(filePath)\n",
    "            with open(filePath, \"rb\") as fhand:\n",
    "                data = fhand.read()\n",
    "                md5Value = hashlib.md5(data).hexdigest()\n",
    "        self.md5Value = str(md5Value)\n",
    "        self._currentName = os.path.basename(filePath)\n",
    "        self._nameRecord = collections.OrderedDict()\n",
    "\n",
    "    def changeFileName(self, newFileName=\"\", stamp=\"\"):\n",
    "        assert newFileName\n",
    "        if not stamp:\n",
    "            stamp = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n",
    "        self._nameRecord[stamp] = self._currentName\n",
    "        self._currentName = newFileName\n",
    "\n",
    "    def getFileNameHistory(self):\n",
    "        return {\n",
    "            self.md5Value: {\n",
    "                \"currentName\": self._currentName,\n",
    "                \"nameRecord\": self._nameRecord\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "def createFileNameLog(filePath=\"\", md5Value=\"\"):\n",
    "    global globalHistoryRecordPath\n",
    "    if not md5Value:\n",
    "        assert os.path.isfile(filePath)\n",
    "        with open(filePath, \"rb\") as fhand:\n",
    "            data = fhand.read()\n",
    "            md5Value = hashlib.md5(data).hexdigest()\n",
    "    fRecordPath = os.path.join(globalHistoryRecordPath,\n",
    "                               str(md5Value) + \"_HRd.pkl\")\n",
    "    if os.path.isfile(fRecordPath):\n",
    "        with open(fRecordPath, \"rb\") as fhand:\n",
    "            rd = pickle.load(fhand)\n",
    "        return rd\n",
    "    else:\n",
    "        assert os.path.isfile(filePath)\n",
    "        return FileNameLog(filePath)\n",
    "\n",
    "\n",
    "def isHiddenFile(path):\n",
    "    if os.name == \"nt\":\n",
    "        import win32api, win32con\n",
    "    if os.name == \"nt\":\n",
    "        attribute = win32api.GetFileAttributes(path)\n",
    "        return attribute & (win32con.FILE_ATTRIBUTE_HIDDEN |\n",
    "                            win32con.FILE_ATTRIBUTE_SYSTEM)\n",
    "    else:\n",
    "        return os.path.basename(path).startswith('.')  #linux-osx\n",
    "\n",
    "\n",
    "def replaceChar(charDict={}, tgtString=\"\"):\n",
    "    global globalFileNameHistoryRecordList\n",
    "    assert charDict\n",
    "    assert tgtString\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    for key, value in charDict.items():\n",
    "        if key in root:\n",
    "            root = root.replace(key, value)\n",
    "            if not globalParameterDictionary[\"simple\"]:\n",
    "                globalFileNameHistoryRecordList.append(root + ext)\n",
    "    return root + ext\n",
    "\n",
    "\n",
    "def processHeadTailChar(tgtString=\"\"):\n",
    "    assert tgtString\n",
    "    specChar = \"_\"\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    if root.startswith(specChar):\n",
    "        root = specChar.join(root.split(specChar)[1:])\n",
    "    if root.endswith(specChar):\n",
    "        root = specChar.join(root.split(specChar)[0:-1])\n",
    "    return root + ext\n",
    "\n",
    "\n",
    "def checkStartsWithTerminology(termDictionary={}, word=\"\"):\n",
    "    for key in termDictionary.keys():\n",
    "        if word.lower().startswith(key):\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "\n",
    "def processTerminology(termDictionary={}, tgtString=\"\"):\n",
    "    assert termDictionary\n",
    "    assert tgtString\n",
    "    specChar = \"_\"\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    wordList = root.split(specChar)\n",
    "    newWordList = []\n",
    "    for word in wordList:\n",
    "        if word.lower() in termDictionary.keys():\n",
    "            newWordList.append(termDictionary[word.lower()])\n",
    "        elif key := checkStartsWithTerminology(termDictionary, word):\n",
    "            newWord = termDictionary[key] + word[len(key):]\n",
    "            newWordList.append(newWord)\n",
    "        else:\n",
    "            newWordList.append(word)\n",
    "    return specChar.join(newWordList) + ext\n",
    "\n",
    "\n",
    "def processWord(wordSet=set(), tgtString=\"\"):\n",
    "    assert wordSet\n",
    "    assert tgtString\n",
    "    specChar = \"_\"\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    wordList = root.split(specChar)\n",
    "    newWordList = []\n",
    "    for word in wordList:\n",
    "        if word.lower() in wordSet:\n",
    "            newWordList.append(string.capwords(word))\n",
    "        else:\n",
    "            newWordList.append(word)\n",
    "\n",
    "    return specChar.join(newWordList) + ext\n",
    "\n",
    "\n",
    "def depthWalk(topPath, topDown=True, followLinks=False, maxDepth=1):\n",
    "    if str(maxDepth).isnumeric():\n",
    "        maxDepth = int(maxDepth)\n",
    "    else:\n",
    "        maxDepth = 1\n",
    "    names = os.listdir(topPath)\n",
    "    dirs, nondirs = [], []\n",
    "    for name in names:\n",
    "        if os.path.isdir(os.path.join(topPath, name)):\n",
    "            dirs.append(name)\n",
    "        else:\n",
    "            nondirs.append(name)\n",
    "    if topDown:\n",
    "        yield topPath, dirs, nondirs\n",
    "    if maxDepth is None or maxDepth > 1:\n",
    "        for name in dirs:\n",
    "            newPath = os.path.join(topPath, name)\n",
    "            if followLinks or not os.path.islink(newPath):\n",
    "                for x in depthWalk(newPath, topDown, followLinks,\n",
    "                                   None if maxDepth is None else maxDepth - 1):\n",
    "                    yield x\n",
    "    if not topDown:\n",
    "        yield topPath, dirs, nondirs\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option(\"--path\",\n",
    "              prompt=\"target path\",\n",
    "              help=\"Recursively traverse path,All files will be changed name.\")\n",
    "@click.option(\"--maxdepth\",\n",
    "              default=1,\n",
    "              type=str,\n",
    "              help=\"Set travel directory tree with max depth\")\n",
    "@click.option(\"--exclude\", default=\"\", help=\"Exclude all files in exclude path\")\n",
    "@click.option(\"--dry\",\n",
    "              default=True,\n",
    "              type=bool,\n",
    "              help=\"If dry is True will not change file name.Default is True.\")\n",
    "@click.option(\n",
    "    \"--simple\",\n",
    "    default=True,\n",
    "    type=bool,\n",
    "    help=\"If simple is True Only print changed file name.Default is True.\")\n",
    "def ufn(path, maxdepth, exclude, dry, simple):\n",
    "    global globalDataPath\n",
    "    global globalParameterDictionary\n",
    "    global globalFileNameHistoryRecordList\n",
    "    \"\"\"Files in PATH will be changed file names unified.\"\"\"\n",
    "    globalParameterDictionary[\"path\"] = path\n",
    "    globalParameterDictionary[\"maxdepth\"] = maxdepth\n",
    "    globalParameterDictionary[\"exclude\"] = exclude\n",
    "    globalParameterDictionary[\"dry\"] = dry\n",
    "    globalParameterDictionary[\"simple\"] = simple\n",
    "    import os\n",
    "    if not os.path.isdir(globalParameterDictionary[\"path\"]):\n",
    "        click.echo(\"%s is not valid path.\")\n",
    "        return -1\n",
    "\n",
    "    with open(os.path.join(globalDataPath, \"CharDictionary.pkl\"),\n",
    "              \"rb\") as fhand:\n",
    "        CharDictionary = pickle.load(fhand)\n",
    "    with open(os.path.join(globalDataPath, \"TerminologyDictionary.pkl\"),\n",
    "              \"rb\") as fhand:\n",
    "        TerminologyDictionary = pickle.load(fhand)\n",
    "    with open(os.path.join(globalDataPath, \"LowerCaseWordSet.pkl\"),\n",
    "              \"rb\") as fhand:\n",
    "        LowerCaseWordSet = pickle.load(fhand)\n",
    "    for subdir, dirs, files in depthWalk(\n",
    "            topPath=globalParameterDictionary[\"path\"],\n",
    "            maxDepth=globalParameterDictionary[\"maxdepth\"]):\n",
    "        for file in files:\n",
    "            #             if not os.path.isfile(file):\n",
    "            #                 continue\n",
    "            globalFileNameHistoryRecordList = []\n",
    "            oldNamePath = os.path.join(subdir, file)\n",
    "            if isHiddenFile(oldNamePath):\n",
    "                continue\n",
    "            newName = file\n",
    "            # replace characters by defined Dictionary\n",
    "            newName = replaceChar(charDict=CharDictionary, tgtString=newName)\n",
    "            # process Head and Tail character exclude file name extension\n",
    "            newName = processHeadTailChar(tgtString=newName)\n",
    "            # Capwords only when word in wordsSet\n",
    "            newName = processWord(wordSet=LowerCaseWordSet, tgtString=newName)\n",
    "            # Pretty Terminology\n",
    "            newName = processTerminology(termDictionary=TerminologyDictionary,\n",
    "                                         tgtString=newName)\n",
    "            # Capitalize The First Letter\n",
    "            newName = newName[0].upper() + newName[1:]\n",
    "            # Create full path\n",
    "            newNamePath = os.path.join(subdir, newName)\n",
    "            if not globalParameterDictionary[\"dry\"]:\n",
    "                # Create Or Update File Name Change Record and Save to File\n",
    "                # then rename file name\n",
    "                if newName != file:\n",
    "                    fileHistoryRecord = createFileNameLog(filePath=oldNamePath)\n",
    "                    with open(\n",
    "                            os.path.join(\n",
    "                                globalHistoryRecordPath,\n",
    "                                str(fileHistoryRecord.md5Value) + \"_HRd.pkl\"),\n",
    "                            \"wb\") as fhand:\n",
    "                        fileHistoryRecord.changeFileName(newFileName=newName)\n",
    "                        pickle.dump(fileHistoryRecord, fhand)\n",
    "                    os.rename(oldNamePath, newNamePath)\n",
    "\n",
    "            if (not globalParameterDictionary[\"simple\"]) or (newName != file):\n",
    "                click.echo(\"   %s\" % file)\n",
    "                for fName in globalFileNameHistoryRecordList:\n",
    "                    click.echo(\"---%s\" % fName)\n",
    "                click.echo(\"==>%s\" % newName)\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scriptDirPath = os.path.dirname(os.path.realpath(__file__))\n",
    "\n",
    "    globalDataPath = os.path.join(scriptDirPath, \"data\")\n",
    "    globalHistoryRecordPath = os.path.join(globalDataPath, \"hRdDir\")\n",
    "\n",
    "    globalParameterDictionary = {}\n",
    "    globalFileNameHistoryRecordList = []\n",
    "\n",
    "    ufn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-illinois",
   "metadata": {},
   "source": [
    "---\n",
    "## Roadmap\n",
    "\n",
    "* colorfull print the difference OldFileName and NewFileName\n",
    "* support undo operation \n",
    "* support set depth\n",
    "* support set ignore directory or files\n",
    "* pretty ShortTerm,such as ATM,ROHS,PCB,...\n",
    "* personalize file name ,such as capatilize every word,...\n",
    "* search all ipynb or python file name and auto correction ...\n",
    "* reserve original file name as link\n",
    "* ensure First Char in Alphabet and Capitalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-craps",
   "metadata": {},
   "source": [
    "## Others ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-millennium",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
